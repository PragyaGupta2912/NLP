{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyONZZE0KaTEuVUIxRGFcazA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PragyaGupta2912/NLP/blob/main/LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dROFSU40fPRJ",
        "outputId": "cb28a698-ad58-4f0b-8c92-a585e6c64c0f"
      },
      "source": [
        "! pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmu8TQcxf_cQ",
        "outputId": "59925015-864c-420f-e9cf-4f633d9596db"
      },
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHkZgWLmgDR7"
      },
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiyKEexWgFYB"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9ABhLGQgH9y",
        "outputId": "de14edf8-59c0-4c6a-89a5-49a99be3abef"
      },
      "source": [
        "! kaggle datasets list"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "ref                                                         title                                              size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  \n",
            "gpreda/reddit-vaccine-myths                                 Reddit Vaccine Myths                              234KB  2021-08-01 09:24:52          10128  \n",
            "crowww/a-large-scale-fish-dataset                           A Large Scale Fish Dataset                          3GB  2021-04-28 17:03:01           6189  \n",
            "imsparsh/musicnet-dataset                                   MusicNet Dataset                                   22GB  2021-02-18 14:12:19           2306  \n",
            "dhruvildave/wikibooks-dataset                               Wikibooks Dataset                                   2GB  2021-07-03 18:37:20           2547  \n",
            "fatiimaezzahra/famous-iconic-women                          Famous Iconic Women                               838MB  2021-02-28 14:56:00           1049  \n",
            "promptcloud/careerbuilder-job-listing-2020                  Careerbuilder Job Listing 2020                     42MB  2021-03-05 06:59:52           1487  \n",
            "alsgroup/end-als                                            End ALS Kaggle Challenge                           12GB  2021-04-08 12:16:37            819  \n",
            "nickuzmenkov/nih-chest-xrays-tfrecords                      NIH Chest X-rays TFRecords                         11GB  2021-03-09 04:49:23            856  \n",
            "mathurinache/twitter-edge-nodes                             Twitter Edge Nodes                                342MB  2021-03-08 06:43:04            696  \n",
            "coloradokb/dandelionimages                                  DandelionImages                                     4GB  2021-02-19 20:03:47            707  \n",
            "imsparsh/accentdb-core-extended                             AccentDB - Core & Extended                          6GB  2021-02-17 14:22:54            124  \n",
            "mathurinache/the-lj-speech-dataset                          The LJ Speech Dataset                               3GB  2021-02-15 09:19:54            261  \n",
            "simiotic/github-code-snippets                               GitHub Code Snippets                                7GB  2021-03-03 11:34:39            249  \n",
            "landrykezebou/lvzhdr-tone-mapping-benchmark-dataset-tmonet  LVZ-HDR Tone Mapping Benchmark Dataset (TMO-Net)   24GB  2021-03-01 05:03:40            163  \n",
            "stuartjames/lights                                          LightS: Light Specularity Dataset                  18GB  2021-02-18 14:32:26            104  \n",
            "nickuzmenkov/ranzcr-clip-kfold-tfrecords                    RANZCR CLiP KFold TFRecords                         2GB  2021-02-21 13:29:51            113  \n",
            "datasnaek/youtube-new                                       Trending YouTube Video Statistics                 201MB  2019-06-03 00:56:47         145736  \n",
            "zynicide/wine-reviews                                       Wine Reviews                                       51MB  2017-11-27 17:08:04         141220  \n",
            "residentmario/ramen-ratings                                 Ramen Ratings                                      40KB  2018-01-11 16:04:39          25379  \n",
            "datasnaek/chess                                             Chess Game Dataset (Lichess)                        3MB  2017-09-04 03:09:09          20367  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeDt4dv-hRyT",
        "outputId": "2ec03bf6-7bfc-47d6-c21e-b3963508f931"
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 19.8 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 3.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73052 sha256=c933ba7ba9094125a19fcafb24607cc54e0d340bf8c140dcfaca6ce35c560e31\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNc47DsBik-j",
        "outputId": "de63c23a-a4d4-4f2b-939b-bb96ca184907"
      },
      "source": [
        "! kaggle datasets list"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ref                                                         title                                              size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "----------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "gpreda/reddit-vaccine-myths                                 Reddit Vaccine Myths                              234KB  2021-08-01 09:24:52          10128        841  1.0              \n",
            "crowww/a-large-scale-fish-dataset                           A Large Scale Fish Dataset                          3GB  2021-04-28 17:03:01           6189        471  0.9375           \n",
            "imsparsh/musicnet-dataset                                   MusicNet Dataset                                   22GB  2021-02-18 14:12:19           2306        175  1.0              \n",
            "dhruvildave/wikibooks-dataset                               Wikibooks Dataset                                   2GB  2021-07-03 18:37:20           2547        197  1.0              \n",
            "fatiimaezzahra/famous-iconic-women                          Famous Iconic Women                               838MB  2021-02-28 14:56:00           1049         87  0.75             \n",
            "promptcloud/careerbuilder-job-listing-2020                  Careerbuilder Job Listing 2020                     42MB  2021-03-05 06:59:52           1487         61  1.0              \n",
            "alsgroup/end-als                                            End ALS Kaggle Challenge                           12GB  2021-04-08 12:16:37            819        120  0.9375           \n",
            "nickuzmenkov/nih-chest-xrays-tfrecords                      NIH Chest X-rays TFRecords                         11GB  2021-03-09 04:49:23            856         46  0.9411765        \n",
            "mathurinache/twitter-edge-nodes                             Twitter Edge Nodes                                342MB  2021-03-08 06:43:04            696         67  1.0              \n",
            "coloradokb/dandelionimages                                  DandelionImages                                     4GB  2021-02-19 20:03:47            707         34  0.75             \n",
            "imsparsh/accentdb-core-extended                             AccentDB - Core & Extended                          6GB  2021-02-17 14:22:54            124         25  0.875            \n",
            "mathurinache/the-lj-speech-dataset                          The LJ Speech Dataset                               3GB  2021-02-15 09:19:54            261         39  1.0              \n",
            "simiotic/github-code-snippets                               GitHub Code Snippets                                7GB  2021-03-03 11:34:39            249         53  1.0              \n",
            "landrykezebou/lvzhdr-tone-mapping-benchmark-dataset-tmonet  LVZ-HDR Tone Mapping Benchmark Dataset (TMO-Net)   24GB  2021-03-01 05:03:40            163         24  0.6875           \n",
            "stuartjames/lights                                          LightS: Light Specularity Dataset                  18GB  2021-02-18 14:32:26            104         24  0.6875           \n",
            "nickuzmenkov/ranzcr-clip-kfold-tfrecords                    RANZCR CLiP KFold TFRecords                         2GB  2021-02-21 13:29:51            113         19  0.875            \n",
            "datasnaek/youtube-new                                       Trending YouTube Video Statistics                 201MB  2019-06-03 00:56:47         145737       4085  0.7941176        \n",
            "zynicide/wine-reviews                                       Wine Reviews                                       51MB  2017-11-27 17:08:04         141220       3121  0.7941176        \n",
            "residentmario/ramen-ratings                                 Ramen Ratings                                      40KB  2018-01-11 16:04:39          25379        623  0.7058824        \n",
            "datasnaek/chess                                             Chess Game Dataset (Lichess)                        3MB  2017-09-04 03:09:09          20367        777  0.8235294        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpfIBhZNkR_L",
        "outputId": "c6d0ca22-0156-4af0-b609-9786304d3051"
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "  Using cached kaggle-1.5.12-py3-none-any.whl\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2msKX1mBki0U",
        "outputId": "8de19f0c-66de-463f-cd69-24dae8225628"
      },
      "source": [
        "!pip install --upgrade kaggle"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcPqQZVVk8fL",
        "outputId": "92002159-3c92-474a-d561-00f171e9a661"
      },
      "source": [
        "!pip uninstall -y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6\n",
        "!kaggle -v"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: kaggle 1.5.12\n",
            "Uninstalling kaggle-1.5.12:\n",
            "  Successfully uninstalled kaggle-1.5.12\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.2.2-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 7.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.2.2\n",
            "Collecting kaggle==1.5.6\n",
            "  Downloading kaggle-1.5.6.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (2021.5.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (5.0.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle==1.5.6) (2.10)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-py3-none-any.whl size=72857 sha256=3233fab2c67c22c9038c705cbdfcfa2d0970414cd8b8d6ce25c0847413abd131\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/e7/e7/eb3c3d514c33294d77ddd5a856bdd58dc9c1fabbed59a02a2b\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Kaggle API 1.5.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOLGizl6lI9v",
        "outputId": "1b068c03-61ba-44be-8edb-d7b32e19b032"
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "  Using cached kaggle-1.5.12-py3-none-any.whl\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.6\n",
            "    Uninstalling kaggle-1.5.6:\n",
            "      Successfully uninstalled kaggle-1.5.6\n",
            "Successfully installed kaggle-1.5.12\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlylaCTylAk3",
        "outputId": "fa365959-83c6-41bd-9191-9c81398f89ff"
      },
      "source": [
        "! kaggle datasets download 'therohk/million-headlines/data'"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading million-headlines.zip to /content\n",
            " 43% 9.00M/21.1M [00:00<00:00, 19.4MB/s]\n",
            "100% 21.1M/21.1M [00:00<00:00, 35.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMeodUv_iz75",
        "outputId": "a1fa274a-6e62-4104-fa73-83fdf45d4124"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json  million-headlines.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpxXHpikoArL",
        "outputId": "2363527c-48b6-4ed8-ebb7-36c8aad60dd3"
      },
      "source": [
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  million-headlines.zip\n",
            "  inflating: abcnews-date-text.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Q5EVATpGvd"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('abcnews-date-text.csv', error_bad_lines=False);\n",
        "data_text = data[['headline_text']]\n",
        "data_text['index'] = data_text.index\n",
        "documents = data_text"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZvjdXAOpMNe",
        "outputId": "cfc44426-2270-45da-e0c6-0f86e6d5a234"
      },
      "source": [
        "print(len(documents))\n",
        "print(documents[:5])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1226258\n",
            "                                       headline_text  index\n",
            "0  aba decides against community broadcasting lic...      0\n",
            "1     act fire witnesses must be aware of defamation      1\n",
            "2     a g calls for infrastructure protection summit      2\n",
            "3           air nz staff in aust strike for pay rise      3\n",
            "4      air nz strike to affect australian travellers      4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxCv2D_GpS1X",
        "outputId": "00182dff-bef5-4d1e-dcd6-7adee7542d5a"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSR1JaqJqnnf",
        "outputId": "7fa86fad-5a9c-489f-8b5f-26938c985797"
      },
      "source": [
        "print(WordNetLemmatizer().lemmatize('went', pos='v'))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "go\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "wGzPQXjjqpdB",
        "outputId": "3558f5c8-d6c1-4530-8b99-e366a99c5efc"
      },
      "source": [
        "stemmer = SnowballStemmer('english')\n",
        "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
        "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
        "           'traditional', 'reference', 'colonizer','plotted']\n",
        "singles = [stemmer.stem(plural) for plural in original_words]\n",
        "pd.DataFrame(data = {'original word': original_words, 'stemmed': singles})"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original word</th>\n",
              "      <th>stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>caresses</td>\n",
              "      <td>caress</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>flies</td>\n",
              "      <td>fli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dies</td>\n",
              "      <td>die</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mules</td>\n",
              "      <td>mule</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>denied</td>\n",
              "      <td>deni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>died</td>\n",
              "      <td>die</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>agreed</td>\n",
              "      <td>agre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>owned</td>\n",
              "      <td>own</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>humbled</td>\n",
              "      <td>humbl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sized</td>\n",
              "      <td>size</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>meeting</td>\n",
              "      <td>meet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>stating</td>\n",
              "      <td>state</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>siezing</td>\n",
              "      <td>siez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>itemization</td>\n",
              "      <td>item</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>sensational</td>\n",
              "      <td>sensat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>traditional</td>\n",
              "      <td>tradit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>reference</td>\n",
              "      <td>refer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>colonizer</td>\n",
              "      <td>colon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>plotted</td>\n",
              "      <td>plot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   original word stemmed\n",
              "0       caresses  caress\n",
              "1          flies     fli\n",
              "2           dies     die\n",
              "3          mules    mule\n",
              "4         denied    deni\n",
              "5           died     die\n",
              "6         agreed    agre\n",
              "7          owned     own\n",
              "8        humbled   humbl\n",
              "9          sized    size\n",
              "10       meeting    meet\n",
              "11       stating   state\n",
              "12       siezing    siez\n",
              "13   itemization    item\n",
              "14   sensational  sensat\n",
              "15   traditional  tradit\n",
              "16     reference   refer\n",
              "17     colonizer   colon\n",
              "18       plotted    plot"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMydj_nXpeGE"
      },
      "source": [
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DGEYanDpiaX",
        "outputId": "8a5c043f-f242-4652-ed09-4d2ff0d81ad9"
      },
      "source": [
        "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
        "\n",
        "print('original document: ')\n",
        "words = []\n",
        "for word in doc_sample.split(' '):\n",
        "    words.append(word)\n",
        "print(words)\n",
        "print('\\n\\n tokenized and lemmatized document: ')\n",
        "print(preprocess(doc_sample))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original document: \n",
            "['ratepayers', 'group', 'wants', 'compulsory', 'local', 'govt', 'voting']\n",
            "\n",
            "\n",
            " tokenized and lemmatized document: \n",
            "['ratepay', 'group', 'want', 'compulsori', 'local', 'govt', 'vote']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em-QPEDcplNu",
        "outputId": "7e5d0bc5-0cd0-4ec9-a5ce-3a8057b39898"
      },
      "source": [
        "processed_docs = documents['headline_text'].map(preprocess)\n",
        "processed_docs[:10]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            [decid, communiti, broadcast, licenc]\n",
              "1                               [wit, awar, defam]\n",
              "2           [call, infrastructur, protect, summit]\n",
              "3                      [staff, aust, strike, rise]\n",
              "4             [strike, affect, australian, travel]\n",
              "5               [ambiti, olsson, win, tripl, jump]\n",
              "6           [antic, delight, record, break, barca]\n",
              "7    [aussi, qualifi, stosur, wast, memphi, match]\n",
              "8            [aust, address, secur, council, iraq]\n",
              "9                         [australia, lock, timet]\n",
              "Name: headline_text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fEtUkd9rB98",
        "outputId": "0d96edf1-b163-4e72-9f24-83d2a6f4c4a5"
      },
      "source": [
        "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 broadcast\n",
            "1 communiti\n",
            "2 decid\n",
            "3 licenc\n",
            "4 awar\n",
            "5 defam\n",
            "6 wit\n",
            "7 call\n",
            "8 infrastructur\n",
            "9 protect\n",
            "10 summit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvFz1P8osE_2"
      },
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjRaopDmsObb",
        "outputId": "6793b711-2a3e-4fb0-e0d6-1a34cd42d873"
      },
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "bow_corpus[4310]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(162, 1), (240, 1), (292, 1), (589, 1), (838, 1), (3570, 1), (3571, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfjLmVwFsQcm",
        "outputId": "9db2e40c-3510-4a27-a705-bf671bc09b1f"
      },
      "source": [
        "bow_doc_4310 = bow_corpus[4310]\n",
        "for i in range(len(bow_doc_4310)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
        "                                               dictionary[bow_doc_4310[i][0]], \n",
        "bow_doc_4310[i][1]))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word 162 (\"govt\") appears 1 time.\n",
            "Word 240 (\"group\") appears 1 time.\n",
            "Word 292 (\"vote\") appears 1 time.\n",
            "Word 589 (\"local\") appears 1 time.\n",
            "Word 838 (\"want\") appears 1 time.\n",
            "Word 3570 (\"compulsori\") appears 1 time.\n",
            "Word 3571 (\"ratepay\") appears 1 time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqnJKx52sdsa",
        "outputId": "6b4634ef-c269-429a-de85-b6c52c6023e6"
      },
      "source": [
        "from gensim import corpora, models\n",
        "tfidf = models.TfidfModel(bow_corpus)\n",
        "corpus_tfidf = tfidf[bow_corpus]\n",
        "from pprint import pprint\n",
        "for doc in corpus_tfidf:\n",
        "    pprint(doc)\n",
        "    break"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.5842699484464488),\n",
            " (1, 0.38798859072167835),\n",
            " (2, 0.5008422243250992),\n",
            " (3, 0.5071987254965034)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRBm24T3sgVw"
      },
      "source": [
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHYxNelDskB1",
        "outputId": "d53a1e70-589f-42de-f330-ef4f3de60a8f"
      },
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.019*\"health\" + 0.018*\"border\" + 0.015*\"australia\" + 0.013*\"interview\" + 0.010*\"say\" + 0.010*\"talk\" + 0.009*\"build\" + 0.009*\"weather\" + 0.009*\"mental\" + 0.008*\"doctor\"\n",
            "Topic: 1 \n",
            "Words: 0.045*\"trump\" + 0.030*\"case\" + 0.030*\"charg\" + 0.029*\"court\" + 0.024*\"murder\" + 0.019*\"face\" + 0.018*\"alleg\" + 0.015*\"jail\" + 0.015*\"accus\" + 0.014*\"woman\"\n",
            "Topic: 2 \n",
            "Words: 0.047*\"coronavirus\" + 0.043*\"covid\" + 0.016*\"tasmania\" + 0.012*\"dead\" + 0.011*\"fund\" + 0.011*\"help\" + 0.011*\"student\" + 0.011*\"communiti\" + 0.010*\"break\" + 0.010*\"indigen\"\n",
            "Topic: 3 \n",
            "Words: 0.039*\"queensland\" + 0.031*\"victoria\" + 0.028*\"sydney\" + 0.027*\"melbourn\" + 0.019*\"coast\" + 0.015*\"coronavirus\" + 0.014*\"australia\" + 0.014*\"farmer\" + 0.012*\"win\" + 0.012*\"gold\"\n",
            "Topic: 4 \n",
            "Words: 0.022*\"home\" + 0.022*\"kill\" + 0.022*\"news\" + 0.019*\"state\" + 0.015*\"peopl\" + 0.014*\"bushfir\" + 0.012*\"child\" + 0.011*\"care\" + 0.011*\"school\" + 0.011*\"abus\"\n",
            "Topic: 5 \n",
            "Words: 0.020*\"open\" + 0.020*\"adelaid\" + 0.016*\"final\" + 0.016*\"island\" + 0.015*\"miss\" + 0.015*\"trial\" + 0.013*\"scott\" + 0.012*\"lose\" + 0.012*\"street\" + 0.010*\"beat\"\n",
            "Topic: 6 \n",
            "Words: 0.057*\"polic\" + 0.025*\"donald\" + 0.017*\"crash\" + 0.016*\"death\" + 0.016*\"shoot\" + 0.015*\"investig\" + 0.013*\"die\" + 0.013*\"royal\" + 0.013*\"morrison\" + 0.012*\"power\"\n",
            "Topic: 7 \n",
            "Words: 0.034*\"coronavirus\" + 0.022*\"nation\" + 0.018*\"south\" + 0.018*\"north\" + 0.017*\"restrict\" + 0.017*\"year\" + 0.016*\"rise\" + 0.015*\"victorian\" + 0.015*\"water\" + 0.012*\"offic\"\n",
            "Topic: 8 \n",
            "Words: 0.039*\"australia\" + 0.021*\"world\" + 0.018*\"market\" + 0.017*\"record\" + 0.017*\"protest\" + 0.015*\"australian\" + 0.015*\"china\" + 0.014*\"busi\" + 0.012*\"time\" + 0.010*\"coronavirus\"\n",
            "Topic: 9 \n",
            "Words: 0.028*\"govern\" + 0.025*\"elect\" + 0.021*\"live\" + 0.020*\"say\" + 0.015*\"chang\" + 0.011*\"labor\" + 0.010*\"speak\" + 0.010*\"drum\" + 0.009*\"andrew\" + 0.009*\"feder\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nion3gkpsmNT",
        "outputId": "f737fc4d-d566-4aaa-b4ac-c18ba47a43bf"
      },
      "source": [
        "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
        "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
        "    print('Topic: {} Word: {}'.format(idx, topic))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 Word: 0.010*\"coronavirus\" + 0.009*\"countri\" + 0.009*\"govern\" + 0.007*\"hour\" + 0.006*\"fund\" + 0.006*\"restrict\" + 0.006*\"queensland\" + 0.005*\"care\" + 0.005*\"budget\" + 0.005*\"commiss\"\n",
            "Topic: 1 Word: 0.013*\"interview\" + 0.009*\"weather\" + 0.006*\"australia\" + 0.005*\"extend\" + 0.005*\"final\" + 0.005*\"quiz\" + 0.005*\"spring\" + 0.005*\"david\" + 0.005*\"storm\" + 0.005*\"wild\"\n",
            "Topic: 2 Word: 0.010*\"climat\" + 0.007*\"mental\" + 0.007*\"chang\" + 0.007*\"john\" + 0.006*\"grandstand\" + 0.006*\"health\" + 0.006*\"senat\" + 0.005*\"octob\" + 0.005*\"march\" + 0.005*\"cancer\"\n",
            "Topic: 3 Word: 0.021*\"news\" + 0.014*\"market\" + 0.014*\"rural\" + 0.012*\"drum\" + 0.008*\"elect\" + 0.008*\"nation\" + 0.008*\"thursday\" + 0.007*\"michael\" + 0.007*\"financ\" + 0.006*\"share\"\n",
            "Topic: 4 Word: 0.009*\"wednesday\" + 0.007*\"peter\" + 0.007*\"lockdown\" + 0.006*\"pacif\" + 0.005*\"august\" + 0.005*\"outback\" + 0.005*\"william\" + 0.005*\"footag\" + 0.005*\"know\" + 0.005*\"decemb\"\n",
            "Topic: 5 Word: 0.008*\"monday\" + 0.008*\"andrew\" + 0.007*\"live\" + 0.006*\"china\" + 0.006*\"korea\" + 0.006*\"price\" + 0.005*\"export\" + 0.005*\"australia\" + 0.005*\"kohler\" + 0.005*\"north\"\n",
            "Topic: 6 Word: 0.026*\"trump\" + 0.015*\"donald\" + 0.013*\"crash\" + 0.009*\"kill\" + 0.008*\"stori\" + 0.008*\"tuesday\" + 0.006*\"polic\" + 0.006*\"dead\" + 0.006*\"turnbul\" + 0.005*\"die\"\n",
            "Topic: 7 Word: 0.009*\"morrison\" + 0.008*\"australia\" + 0.008*\"scott\" + 0.007*\"sport\" + 0.007*\"coronavirus\" + 0.007*\"world\" + 0.006*\"cricket\" + 0.006*\"pandem\" + 0.006*\"alan\" + 0.005*\"zealand\"\n",
            "Topic: 8 Word: 0.016*\"murder\" + 0.015*\"charg\" + 0.013*\"polic\" + 0.012*\"death\" + 0.011*\"court\" + 0.011*\"woman\" + 0.009*\"alleg\" + 0.009*\"sentenc\" + 0.009*\"assault\" + 0.008*\"guilti\"\n",
            "Topic: 9 Word: 0.014*\"coronavirus\" + 0.011*\"covid\" + 0.009*\"friday\" + 0.007*\"updat\" + 0.007*\"christma\" + 0.006*\"vaccin\" + 0.006*\"australia\" + 0.006*\"quarantin\" + 0.005*\"novemb\" + 0.005*\"mount\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwzHHM6asolI",
        "outputId": "9e278c2a-fde6-47d0-e26d-c7b5ce606aa6"
      },
      "source": [
        "processed_docs[4310]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ratepay', 'group', 'want', 'compulsori', 'local', 'govt', 'vote']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gle8CrsTsrNN",
        "outputId": "261e3a36-7d92-4ea9-8c9c-9e44861113d8"
      },
      "source": [
        "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Score: 0.8874966502189636\t \n",
            "Topic: 0.028*\"govern\" + 0.025*\"elect\" + 0.021*\"live\" + 0.020*\"say\" + 0.015*\"chang\" + 0.011*\"labor\" + 0.010*\"speak\" + 0.010*\"drum\" + 0.009*\"andrew\" + 0.009*\"feder\"\n",
            "\n",
            "Score: 0.012502153404057026\t \n",
            "Topic: 0.047*\"coronavirus\" + 0.043*\"covid\" + 0.016*\"tasmania\" + 0.012*\"dead\" + 0.011*\"fund\" + 0.011*\"help\" + 0.011*\"student\" + 0.011*\"communiti\" + 0.010*\"break\" + 0.010*\"indigen\"\n",
            "\n",
            "Score: 0.012500587850809097\t \n",
            "Topic: 0.034*\"coronavirus\" + 0.022*\"nation\" + 0.018*\"south\" + 0.018*\"north\" + 0.017*\"restrict\" + 0.017*\"year\" + 0.016*\"rise\" + 0.015*\"victorian\" + 0.015*\"water\" + 0.012*\"offic\"\n",
            "\n",
            "Score: 0.012500576674938202\t \n",
            "Topic: 0.039*\"australia\" + 0.021*\"world\" + 0.018*\"market\" + 0.017*\"record\" + 0.017*\"protest\" + 0.015*\"australian\" + 0.015*\"china\" + 0.014*\"busi\" + 0.012*\"time\" + 0.010*\"coronavirus\"\n",
            "\n",
            "Score: 0.012499998323619366\t \n",
            "Topic: 0.019*\"health\" + 0.018*\"border\" + 0.015*\"australia\" + 0.013*\"interview\" + 0.010*\"say\" + 0.010*\"talk\" + 0.009*\"build\" + 0.009*\"weather\" + 0.009*\"mental\" + 0.008*\"doctor\"\n",
            "\n",
            "Score: 0.012499998323619366\t \n",
            "Topic: 0.045*\"trump\" + 0.030*\"case\" + 0.030*\"charg\" + 0.029*\"court\" + 0.024*\"murder\" + 0.019*\"face\" + 0.018*\"alleg\" + 0.015*\"jail\" + 0.015*\"accus\" + 0.014*\"woman\"\n",
            "\n",
            "Score: 0.012499998323619366\t \n",
            "Topic: 0.039*\"queensland\" + 0.031*\"victoria\" + 0.028*\"sydney\" + 0.027*\"melbourn\" + 0.019*\"coast\" + 0.015*\"coronavirus\" + 0.014*\"australia\" + 0.014*\"farmer\" + 0.012*\"win\" + 0.012*\"gold\"\n",
            "\n",
            "Score: 0.012499998323619366\t \n",
            "Topic: 0.022*\"home\" + 0.022*\"kill\" + 0.022*\"news\" + 0.019*\"state\" + 0.015*\"peopl\" + 0.014*\"bushfir\" + 0.012*\"child\" + 0.011*\"care\" + 0.011*\"school\" + 0.011*\"abus\"\n",
            "\n",
            "Score: 0.012499998323619366\t \n",
            "Topic: 0.020*\"open\" + 0.020*\"adelaid\" + 0.016*\"final\" + 0.016*\"island\" + 0.015*\"miss\" + 0.015*\"trial\" + 0.013*\"scott\" + 0.012*\"lose\" + 0.012*\"street\" + 0.010*\"beat\"\n",
            "\n",
            "Score: 0.012499998323619366\t \n",
            "Topic: 0.057*\"polic\" + 0.025*\"donald\" + 0.017*\"crash\" + 0.016*\"death\" + 0.016*\"shoot\" + 0.015*\"investig\" + 0.013*\"die\" + 0.013*\"royal\" + 0.013*\"morrison\" + 0.012*\"power\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZYv9wE1stFV",
        "outputId": "2bbc962f-79c6-4b2d-db61-a123babde8a0"
      },
      "source": [
        "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Score: 0.73236483335495\t \n",
            "Topic: 0.010*\"coronavirus\" + 0.009*\"countri\" + 0.009*\"govern\" + 0.007*\"hour\" + 0.006*\"fund\" + 0.006*\"restrict\" + 0.006*\"queensland\" + 0.005*\"care\" + 0.005*\"budget\" + 0.005*\"commiss\"\n",
            "\n",
            "Score: 0.16762429475784302\t \n",
            "Topic: 0.026*\"trump\" + 0.015*\"donald\" + 0.013*\"crash\" + 0.009*\"kill\" + 0.008*\"stori\" + 0.008*\"tuesday\" + 0.006*\"polic\" + 0.006*\"dead\" + 0.006*\"turnbul\" + 0.005*\"die\"\n",
            "\n",
            "Score: 0.012502939440310001\t \n",
            "Topic: 0.021*\"news\" + 0.014*\"market\" + 0.014*\"rural\" + 0.012*\"drum\" + 0.008*\"elect\" + 0.008*\"nation\" + 0.008*\"thursday\" + 0.007*\"michael\" + 0.007*\"financ\" + 0.006*\"share\"\n",
            "\n",
            "Score: 0.012502810917794704\t \n",
            "Topic: 0.008*\"monday\" + 0.008*\"andrew\" + 0.007*\"live\" + 0.006*\"china\" + 0.006*\"korea\" + 0.006*\"price\" + 0.005*\"export\" + 0.005*\"australia\" + 0.005*\"kohler\" + 0.005*\"north\"\n",
            "\n",
            "Score: 0.012501583434641361\t \n",
            "Topic: 0.010*\"climat\" + 0.007*\"mental\" + 0.007*\"chang\" + 0.007*\"john\" + 0.006*\"grandstand\" + 0.006*\"health\" + 0.006*\"senat\" + 0.005*\"octob\" + 0.005*\"march\" + 0.005*\"cancer\"\n",
            "\n",
            "Score: 0.012501131743192673\t \n",
            "Topic: 0.009*\"wednesday\" + 0.007*\"peter\" + 0.007*\"lockdown\" + 0.006*\"pacif\" + 0.005*\"august\" + 0.005*\"outback\" + 0.005*\"william\" + 0.005*\"footag\" + 0.005*\"know\" + 0.005*\"decemb\"\n",
            "\n",
            "Score: 0.012500830926001072\t \n",
            "Topic: 0.014*\"coronavirus\" + 0.011*\"covid\" + 0.009*\"friday\" + 0.007*\"updat\" + 0.007*\"christma\" + 0.006*\"vaccin\" + 0.006*\"australia\" + 0.006*\"quarantin\" + 0.005*\"novemb\" + 0.005*\"mount\"\n",
            "\n",
            "Score: 0.012500646524131298\t \n",
            "Topic: 0.009*\"morrison\" + 0.008*\"australia\" + 0.008*\"scott\" + 0.007*\"sport\" + 0.007*\"coronavirus\" + 0.007*\"world\" + 0.006*\"cricket\" + 0.006*\"pandem\" + 0.006*\"alan\" + 0.005*\"zealand\"\n",
            "\n",
            "Score: 0.012500454671680927\t \n",
            "Topic: 0.013*\"interview\" + 0.009*\"weather\" + 0.006*\"australia\" + 0.005*\"extend\" + 0.005*\"final\" + 0.005*\"quiz\" + 0.005*\"spring\" + 0.005*\"david\" + 0.005*\"storm\" + 0.005*\"wild\"\n",
            "\n",
            "Score: 0.012500452809035778\t \n",
            "Topic: 0.016*\"murder\" + 0.015*\"charg\" + 0.013*\"polic\" + 0.012*\"death\" + 0.011*\"court\" + 0.011*\"woman\" + 0.009*\"alleg\" + 0.009*\"sentenc\" + 0.009*\"assault\" + 0.008*\"guilti\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vEkCU72svw2",
        "outputId": "1d0cce1b-3ff4-42fb-f104-5adafceb70b9"
      },
      "source": [
        "unseen_document = 'How a Pentagon deal became an identity crisis for Google'\n",
        "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
        "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.3500000536441803\t Topic: 0.039*\"australia\" + 0.021*\"world\" + 0.018*\"market\" + 0.017*\"record\" + 0.017*\"protest\"\n",
            "Score: 0.1833333820104599\t Topic: 0.019*\"health\" + 0.018*\"border\" + 0.015*\"australia\" + 0.013*\"interview\" + 0.010*\"say\"\n",
            "Score: 0.18333332240581512\t Topic: 0.039*\"queensland\" + 0.031*\"victoria\" + 0.028*\"sydney\" + 0.027*\"melbourn\" + 0.019*\"coast\"\n",
            "Score: 0.18333323299884796\t Topic: 0.028*\"govern\" + 0.025*\"elect\" + 0.021*\"live\" + 0.020*\"say\" + 0.015*\"chang\"\n",
            "Score: 0.01666666753590107\t Topic: 0.045*\"trump\" + 0.030*\"case\" + 0.030*\"charg\" + 0.029*\"court\" + 0.024*\"murder\"\n",
            "Score: 0.01666666753590107\t Topic: 0.047*\"coronavirus\" + 0.043*\"covid\" + 0.016*\"tasmania\" + 0.012*\"dead\" + 0.011*\"fund\"\n",
            "Score: 0.01666666753590107\t Topic: 0.022*\"home\" + 0.022*\"kill\" + 0.022*\"news\" + 0.019*\"state\" + 0.015*\"peopl\"\n",
            "Score: 0.01666666753590107\t Topic: 0.020*\"open\" + 0.020*\"adelaid\" + 0.016*\"final\" + 0.016*\"island\" + 0.015*\"miss\"\n",
            "Score: 0.01666666753590107\t Topic: 0.057*\"polic\" + 0.025*\"donald\" + 0.017*\"crash\" + 0.016*\"death\" + 0.016*\"shoot\"\n",
            "Score: 0.01666666753590107\t Topic: 0.034*\"coronavirus\" + 0.022*\"nation\" + 0.018*\"south\" + 0.018*\"north\" + 0.017*\"restrict\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETK9T2eHsyVG"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}